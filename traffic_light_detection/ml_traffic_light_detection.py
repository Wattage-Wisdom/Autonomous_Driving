# -*- coding: utf-8 -*-
"""ML_traffic_light_detection.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/13HhSqQYd2RsJ2tHxtRfBcoIoUenNGLnL
"""

#Mount drive in Colab enviroment
from google.colab import drive
drive.mount('/content/drive')

#Import proper libraries
import sys
import cv2
import numpy as np
from PIL import Image
import os
import tensorflow as tf
from tensorflow.keras import datasets, layers, models
import matplotlib.pyplot as plt
import numpy as np
from sklearn.model_selection import train_test_split

#Define directories for training images
green_dir = "/content/drive/MyDrive/Traffic_Light_Detection/saved_images/green"
yellow_dir = "/content/drive/MyDrive/Traffic_Light_Detection/saved_images/yellow"
red_dir = "/content/drive/MyDrive/Traffic_Light_Detection/saved_images/red"

"""Sort through directories and assign proper labels"""

#Define lists for training images
red_images = []
yellow_images = []
green_images = []

#Define new size of image to be resized when loading
new_size = (180, 180)

#Create loops to load image from directory using cv2, resize the image, and append it to the appropriate list

#Load red pictures and assign a label
files = os.listdir(red_dir)
for file_name in files:
  if file_name.lower().endswith(('.png', '.jpg', '.jpeg', '.gif')):
    file_path = os.path.join(red_dir, file_name)
    image = cv2.imread(file_path)
    resized_img = cv2.resize(image, new_size, interpolation=cv2.INTER_AREA)
    red_images.append(resized_img)

#Load yellow pictures and assign a label
files = os.listdir(yellow_dir)
for file_name in files:
  if file_name.lower().endswith(('.png', '.jpg', '.jpeg', '.gif')):
    file_path = os.path.join(yellow_dir, file_name)
    image = cv2.imread(file_path)
    resized_img = cv2.resize(image, new_size, interpolation=cv2.INTER_AREA)
    yellow_images.append(resized_img)

#Load green pictures and assign a label
files = os.listdir(green_dir)
for file_name in files:
  if file_name.lower().endswith(('.png', '.jpg', '.jpeg', '.gif')):
    file_path = os.path.join(green_dir, file_name)
    image = cv2.imread(file_path)
    resized_img = cv2.resize(image, new_size, interpolation=cv2.INTER_AREA)
    green_images.append(resized_img)

#View amount of data for each label
print(len(red_images))
print(len(yellow_images))
print(len(green_images))
#View shape to assure resized correctly
print(red_images[0].shape)

#Define lists to hold images and associated labels
image_data = []
label_data = []

#Create loops to append images into same list and add associated label to label list

#Add red images to data train
for image in red_images:
  image_data.append(image)
  label_data.append(0)

#Add yellow images to data train
for image in yellow_images:
  image_data.append(image)
  label_data.append(1)

#Add green images to data train
for image in green_images:
  image_data.append(image)
  label_data.append(2)

#Assure proper labels are indexed
print(label_data[1]) #Should be red (0)
print(label_data[78]) #Should be yellow (1)
print(label_data[135]) #Should be green (2)

#Perform a training/test split on the data and make sure to shuffle data for even split
x_train, x_test, y_train, y_test = train_test_split(image_data, label_data, test_size = 0.2, shuffle = True)

#Change train data to numpy array and label to integer
x_train = np.array(x_train)
y_train = [int(y) for y in y_train]
y_train = np.array(y_train)

#Change test data to numpy array and label to integer
x_test = np.array(x_test)
y_test = [int(y) for y in y_test]
y_test = np.array(y_test)

"""Build and Train the Model"""

#Specify input parameters
batch_size = 32
img_height = 180
img_width = 180

#Build the sequential Convolutional Neural Network
model = models.Sequential()

#Add desired layers below:

#Rescaling layer reshapes image to the proper input size and normalizes the image
model.add(layers.Rescaling(1./255, input_shape=(img_height, img_width, 3)))
#1st set of convolutional and pooling layers
model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)))
model.add(layers.MaxPooling2D((2, 2)))
#2nd set of convolutional and pooling layers
model.add(layers.Conv2D(64, (3, 3), activation='relu'))
model.add(layers.MaxPooling2D((2, 2)))
#3rd set of convolutional and pooling layers
model.add(layers.Conv2D(64, (3, 3), activation='relu'))
model.add(layers.MaxPooling2D((2, 2)))
#4th set of convolutional and pooling layers
model.add(layers.Conv2D(64, (3, 3), activation='relu'))
model.add(layers.MaxPooling2D((2, 2)))
#Final convolutional layer
model.add(layers.Conv2D(64, (3, 3), activation='relu'))
#Flattens the image to 1 dimension
model.add(layers.Flatten())
#Dense layer for classification
model.add(layers.Dense(64, activation='relu'))
#Final output layer, 3 neurons as 3 light classifications
model.add(layers.Dense(3))

#Veiw summary of the model including number of parameters
model.summary()

#Compile the model to prepare it for training
model.compile(
    optimizer='adam', #Adam optimizer for adaptive moment estimation
    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), #Loss function for multiclass classifier
    metrics=['accuracy']) #Specify desired metrics to be monitored

"""Evaluate and save the trained model"""

#Train the model for 35 epochs, save training metrics for later display
history = model.fit(x_train, y_train, epochs=40,
                    validation_data=(x_test, y_test))

#Display model metrics recorded during training (look for signs of overfitting)
plt.plot(history.history['accuracy'], label='accuracy')
plt.plot(history.history['val_accuracy'], label = 'val_accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.ylim([0.5, 1])
plt.legend(loc='lower right')

#Test models accuracy on test data
test_loss, test_acc = model.evaluate(x_test,  y_test, verbose=2)

#Create directory to save model if it does not exist
model_dir = "/content/drive/MyDrive/Traffic_Light_Detection/saved_models/"
if not os.path.exists(model_dir):
    os.makedirs(model_dir)

#Give the saved model a name
model_name = 'CNN_1'

#Save the trained model
model.save(os.path.join(model_dir, model_name))

"""Reload the saved model and view summary/test accuracy"""

#Specify saved model directory
model_dir = "/content/drive/MyDrive/Traffic_Light_Detection/saved_models/"

#Recall specific model you wish to reload
model_name = 'CNN_1'

#Load the saved model
new_model = tf.keras.models.load_model(os.path.join(model_dir, model_name))

#View summary of the saved model and test its performance
new_model.summary()
loss, acc = new_model.evaluate(x_test,  y_test, verbose=2)

"""Use the reloaded model to generate predictions"""

#Add a softmax layer to the model to turn logits to probabilities
prediction_model = models.Sequential([new_model,
                                      layers.Softmax()])

#Generate prediction
predictions = prediction_model.predict(x_test)

#Pull out the models prediction and view it compared to its associated label
print(np.argmax(predictions[20]))
print(y_test[20])